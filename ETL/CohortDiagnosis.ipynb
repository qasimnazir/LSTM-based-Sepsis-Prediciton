{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"PySpark","language":"python","name":"pyspark"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"colab":{"name":"CohortDiagnosis.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"code","metadata":{"id":"8dzeSK-5fty7"},"source":["import pyspark\n","import time\n","from pyspark.sql import SparkSession\n","from pyspark.sql.functions import *\n","from pyspark.sql.types import *\n","from pyspark.sql.window import Window\n","from random import sample\n","import random\n","\n","spark = SparkSession.builder.getOrCreate() "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"F0Ouz3jTfty_"},"source":["#Hardcode schema to speed up data read\n","#Code Reference:https://github.com/MIT-LCP/mimic-code/blob/master/buildmimic/aws-athena/mimictoparquet_glue_job.py\n","schema_icustays = StructType([\n","    StructField(\"row_id\", IntegerType()),\n","    StructField(\"subject_id\", IntegerType()),\n","    StructField(\"hadm_id\", IntegerType()),\n","    StructField(\"icustay_id\", IntegerType()),\n","    StructField(\"dbsource\", StringType()),\n","    StructField(\"first_careunit\", StringType()),\n","    StructField(\"last_careunit\", StringType()),\n","    StructField(\"first_wardid\", ShortType()),\n","    StructField(\"last_wardid\", ShortType()),\n","    StructField(\"intime\", TimestampType()),\n","    StructField(\"outtime\", TimestampType()),\n","    StructField(\"los\", DoubleType())\n","])\n","\n","schema_patients = StructType([\n","    StructField(\"row_id\", IntegerType()),\n","    StructField(\"subject_id\", IntegerType()),\n","    StructField(\"gender\", StringType()),\n","    StructField(\"dob\", TimestampType()),\n","    StructField(\"dod\", TimestampType()),\n","    StructField(\"dod_hosp\", TimestampType()),\n","    StructField(\"dod_ssn\", TimestampType()),\n","    StructField(\"expire_flag\", IntegerType())\n","])\n","\n","schema_services = StructType([\n","    StructField(\"row_id\", IntegerType()),\n","    StructField(\"subject_id\", IntegerType()),\n","    StructField(\"hadm_id\", IntegerType()),\n","    StructField(\"transfertime\", TimestampType()),\n","    StructField(\"prev_service\", StringType()),\n","    StructField(\"curr_service\", StringType())\n","])\n","\n","schema_chartevents = StructType([\n","    StructField(\"row_id\", IntegerType()),\n","    StructField(\"subject_id\", IntegerType()),\n","    StructField(\"hadm_id\", IntegerType()),\n","    StructField(\"icustay_id\", IntegerType()),\n","    StructField(\"itemid\", IntegerType()),\n","    StructField(\"charttime\", TimestampType()),\n","    StructField(\"storetime\", TimestampType()),\n","    StructField(\"cgid\", IntegerType()),\n","    StructField(\"value\", StringType()),\n","    StructField(\"valuenum\", DoubleType()),\n","    StructField(\"valueuom\", StringType()),\n","    StructField(\"warning\", IntegerType()),\n","    StructField(\"error\", IntegerType()),\n","    StructField(\"resultstatus\", StringType()),\n","    StructField(\"stopped\", StringType())\n","])\n","\n","\n","schema_ditems = StructType([\n","    StructField(\"row_id\", IntegerType()),\n","    StructField(\"itemid\", IntegerType()),\n","    StructField(\"label\", StringType()),\n","    StructField(\"abbreviation\", StringType()),\n","    StructField(\"dbsource\", StringType()),\n","    StructField(\"linksto\", StringType()),\n","    StructField(\"category\", StringType()),\n","    StructField(\"unitname\", StringType()),\n","    StructField(\"param_type\", StringType()),\n","    StructField(\"conceptid\", IntegerType())\n","])\n","\n","schema_admissions = StructType([\n","    StructField(\"row_id\", IntegerType()),\n","    StructField(\"subject_id\", IntegerType()),\n","    StructField(\"hadm_id\", IntegerType()),\n","    StructField(\"admittime\", TimestampType()),\n","    StructField(\"dischtime\", TimestampType()),\n","    StructField(\"deathtime\", TimestampType()),\n","    StructField(\"admission_type\", StringType()),\n","    StructField(\"admission_location\", StringType()),\n","    StructField(\"discharge_location\", StringType()),\n","    StructField(\"insurance\", StringType()),\n","    StructField(\"language\", StringType()),\n","    StructField(\"religion\", StringType()),\n","    StructField(\"marital_status\", StringType()),\n","    StructField(\"ethnicity\", StringType()),\n","    StructField(\"edregtime\", TimestampType()),\n","    StructField(\"edouttime\", TimestampType()),\n","    StructField(\"diagnosis\", StringType()),\n","    StructField(\"hospital_expire_flag\", ShortType()),\n","    StructField(\"has_chartevents_data\", ShortType())\n","])\n","\n","\n","schema_fio2 = StructType([\n","    StructField(\"icustay_id\", IntegerType()),\n","    StructField(\"charttime\", TimestampType()),\n","    StructField(\"fio2\", DoubleType())\n","    \n","])\n","\n","schema_gcs = StructType([\n","    StructField(\"icustay_id\", IntegerType()),\n","    StructField(\"charttime\", TimestampType()),\n","    StructField(\"gcs\", DoubleType()),\n","    StructField(\"gcsmotor\", DoubleType()),\n","    StructField(\"gcsverbal\", DoubleType()),\n","    StructField(\"gcseyes\", DoubleType()),\n","    StructField(\"endotrachflag\", IntegerType())    \n","])\n","\n","schema_sofa = StructType([\n","    StructField(\"icustay_id\", IntegerType()),\n","    StructField(\"hr\", IntegerType()),\n","    StructField(\"starttime\", TimestampType()),\n","    StructField(\"endtime\", TimestampType()),\n","    StructField(\"sofa_24hours\", IntegerType())\n","])\n","\n","schema_vital = StructType([\n","    StructField(\"icustay_id\", IntegerType()),\n","    StructField(\"charttime\", TimestampType()),\n","    StructField(\"heartrate\", DoubleType()),\n","    StructField(\"sysbp\", DoubleType()),\n","    StructField(\"diasbp\", DoubleType()),\n","    StructField(\"meanbp\", DoubleType()),\n","    StructField(\"resprate\", DoubleType()),\n","    StructField(\"tempc\", DoubleType()),\n","    StructField(\"spo2\", DoubleType()),\n","    StructField(\"glucose\", DoubleType())\n","])\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dzLM9DDcftzD"},"source":["#Source Tables\n","#Postgres Tables\n","df_icustays = spark.read.csv('gs://peaceful-bruin-307600/db/ICUSTAYS.csv', sep = ',', schema = schema_icustays, header = True)\n","df_patients = spark.read.csv('gs://peaceful-bruin-307600/db/PATIENTS.csv', sep = ',', schema = schema_patients, header = True)\n","df_services = spark.read.csv('gs://peaceful-bruin-307600/db/SERVICES.csv', sep = ',', schema = schema_services, header = True)\n","df_chartevents = spark.read.csv('gs://peaceful-bruin-307600/db/CHARTEVENTS.csv', sep = ',', schema = schema_chartevents, header = True)\n","df_admissions = spark.read.csv('gs://peaceful-bruin-307600/db/ADMISSIONS.csv', sep = ',', schema = schema_admissions, header = True)\n","df_ditems = spark.read.csv('gs://peaceful-bruin-307600/db/D_ITEMS.csv', sep = ',', schema = schema_ditems, header = True)\n","df_sepsis_no_exclusion = spark.read.csv('gs://peaceful-bruin-307600/sepsis3-df-no-exclusions.csv', sep = ',', inferSchema= True, header = True)\n","\n","#Derived Physionet Tables\n","df_fio2 = spark.read.csv('gs://peaceful-bruin-307600/derived/fio2.csv', sep = ',', schema = schema_fio2, header = True)\n","df_gcs = spark.read.csv('gs://peaceful-bruin-307600/derived/gcs.csv', sep = ',', schema = schema_gcs, header = True)\n","df_sofa = spark.read.csv('gs://peaceful-bruin-307600/derived/sofa_direct', sep = ',', schema = schema_sofa, header = True)\n","df_vital = spark.read.csv('gs://peaceful-bruin-307600/derived/vital.csv', sep = ',', schema = schema_vital, header = True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rkf1yuSSftzF"},"source":["#Create Temporary Tables for query\n","df_icustays.registerTempTable('icustays')\n","df_patients.registerTempTable('patients')\n","df_services.registerTempTable('services')\n","df_chartevents.registerTempTable('chartevents')\n","df_admissions.registerTempTable('admissions')\n","df_ditems.registerTempTable('ditems')\n","df_fio2.registerTempTable('fio2')\n","df_gcs.registerTempTable('gcs')\n","df_sofa.registerTempTable('sofa')\n","df_vital.registerTempTable('vital')\n","df_sepsis_no_exclusion.registerTempTable('sepsis3')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"spRAP3_3ftzH"},"source":["#Get Suspected infection time for each icustay_id\n","query = \\\n","\"\"\"\n","select\n","    Distinct\n","    icustay_id\n","    ,suspected_infection_time_poe\n","    ,suspected_infection_time_poe_days\n","\n","from sepsis3\n","    Where suspected_infection_time_poe is NOT NULL\n","\"\"\"\n","\n","df_susp_inf = spark.sql(query)\n","df_susp_inf.registerTempTable('susp_inf')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vyj_8oRrftzI"},"source":["#Create Cohort\n","#Code Reference: https://github.com/MIT-LCP/mimic-code/blob/7ff270c7079a42621f6e011de6ce4ddc0f7fd45c/tutorials/cohort-selection.ipynb\n","#Code Reference: https://github.com/alistairewj/sepsis3-mimic/blob/master/query/tbls/cohort.sql\n","query = \\\n","\"\"\"\n","WITH co AS\n","(\n","SELECT \n","icu.subject_id\n",",icu.hadm_id\n",",icu.icustay_id\n",",icu.dbsource\n",",first_careunit\n",",los as icu_length_of_stay\n",",icu.intime\n",",icu.outtime\n",",DATEDIFF (icu.intime , pat.dob )/365 as age\n",",pat.gender\n",",adm.ethnicity\n",",adm.HAS_CHARTEVENTS_DATA\n",",RANK() OVER (PARTITION BY icu.subject_id ORDER BY icu.intime) AS icustay_id_order\n","FROM icustays icu\n","INNER JOIN patients pat ON icu.subject_id = pat.subject_id\n","INNER JOIN admissions adm ON icu.hadm_id = adm.hadm_id\n","--LIMIT 10\n",")\n",",serv AS\n","(\n","SELECT \n","icu.*\n",",se.curr_service\n",",CASE\n","--WHEN curr_service like '%SURG' then 1\n","--WHEN curr_service = 'ORTHO' then 1\n","WHEN curr_service in ('CSURG','VSURG','TSURG') then 1\n","ELSE 0 END\n","as surgical\n",",RANK() OVER (PARTITION BY icu.hadm_id ORDER BY se.transfertime DESC) as rank\n","FROM icustays icu\n","LEFT JOIN services se ON icu.hadm_id = se.hadm_id\n","--AND se.transfertime < icu.intime + interval '12' hour\n",")\n","\n","SELECT\n","co.*\n",",CASE\n","WHEN co.icu_length_of_stay < .5 then 1\n","ELSE 0 END\n","AS exclusion_los\n",",CASE\n","WHEN co.age <= 16 then 1\n","ELSE 0 END\n","AS exclusion_age\n",",CASE \n","WHEN co.icustay_id_order != 1 THEN 1\n","ELSE 0 END \n","AS exclusion_first_stay\n",",CASE\n","WHEN serv.surgical == 1 THEN 1\n","ELSE 0 END\n","as exclusion_surgical\n",",CASE\n","when co.dbsource != 'metavision' THEN 1\n","ELSE 0 END \n","as exclusion_icu_db\n",",Case \n","when co.HAS_CHARTEVENTS_DATA == 0 then 1\n","when co.intime is null then 1\n","when co.outtime is null then 1\n","else 0 end \n","as exclusion_bad_data\n","\n",",inf.suspected_infection_time_poe\n",",inf.suspected_infection_time_poe - INTERVAL 48 HOURS as inf_window_start\n",",inf.suspected_infection_time_poe + INTERVAL 24 HOURS as inf_window_end\n","\n","--Exclude cases where there is no overlap with suspected infection window\n",",Case \n","--The line below limits suspected infection that occur outside the end of the ICU Stay to ensure at least 12 hours of data are avaliable for SOFA score window\n","when (inf.suspected_infection_time_poe - INTERVAL 48 HOURS) > (co.outtime - INTERVAL 12 HOURS) Then 1\n","--The line below limits suspected infection time to within 12 hours prior to ICU stay to ensure enough data points for sofa window \n","--Cuts out Noise for specificity as suspected infection time is often round to day and can lead to misleading no sepsis diagnosis ground truth\n","when (inf.suspected_infection_time_poe + INTERVAL 24 HOURS ) < (co.intime + INTERVAL 12 HOURS) Then 1\n","else 0 end \n","as exclusion_sus_inf_window\n","\n","FROM co\n","LEFT JOIN serv ON co.icustay_id = serv.icustay_id AND serv.rank = 1\n","LEFT JOIN susp_inf inf ON (co.icustay_id = inf.icustay_id)\n","\n","\"\"\"    \n","df_cohort_no_exclusion = spark.sql(query)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KzGp5hK_ftzK","outputId":"edec235a-4e81-459a-9106-7b3a2997af0e"},"source":["#Filter Cohort for Exclusions\n","df_cohort_exclusion = df_cohort_no_exclusion.filter((df_cohort_no_exclusion.exclusion_age == 0)\n","                                                    & (df_cohort_no_exclusion.exclusion_first_stay == 0)\n","                                                    & (df_cohort_no_exclusion.exclusion_surgical == 0) \n","                                                    & (df_cohort_no_exclusion.exclusion_icu_db == 0)\n","                                                    & (df_cohort_no_exclusion.exclusion_bad_data == 0)\n","                                                    & (df_cohort_no_exclusion.exclusion_sus_inf_window == 0)\n","                                                    & (df_cohort_no_exclusion.exclusion_los == 0)) \n","\n","df_cohort_exclusion.registerTempTable('cohort_exclusion')\n","df_cohort_exclusion.count()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["8569"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"8pjHbze_ftzO"},"source":["#Create TS data with an additional field of array time sequences by hour between the intime and outtime for a subjet_id, icustay_id\n","#Code Reference: https://stackoverflow.com/questions/43141671/sparksql-on-pyspark-how-to-generate-time-series\n","query = \\\n","\"\"\"\n","SELECT\n","ce.*\n",",DATE_TRUNC('hour', ce.intime) as intime_round\n",",DATE_TRUNC('hour', ce.outtime)+ INTERVAL 1 HOURS as outtime_round\n",",sequence(to_timestamp(DATE_TRUNC('hour', ce.intime)), to_timestamp(DATE_TRUNC('hour', ce.outtime)), interval 1 hour) as time\n","\n","FROM cohort_exclusion ce\n","\"\"\"\n","df_cohort_exclusion_ts = sqlContext.sql(query)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tE-s9e59ftzP"},"source":["#Explode the array field for each row into multiple rows to create a time series template\n","#df_cohort_exclusion_ts = df_cohort_exclusion_ts.withColumn(\"timestamp\", explode(col(\"time\"))).drop(col(\"time\"))\n","df_cohort_exclusion_ts = df_cohort_exclusion_ts.select(\"*\", posexplode(col(\"time\"))).drop(col(\"time\"))\n","df_cohort_exclusion_ts = df_cohort_exclusion_ts.withColumnRenamed('col', 'timestamp')\n","df_cohort_exclusion_ts = df_cohort_exclusion_ts.withColumnRenamed('pos', 'hour')\n","\n","#Register Table for querying\n","df_cohort_exclusion_ts.registerTempTable('cohort_exclusion_ts')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UHc4ng9YftzQ"},"source":["#Cleanse sofa prior to joining\n","query = \\\n","\"\"\"\n","select \n","    s.icustay_id\n","    ,s.hr\n","    ,s.starttime\n","    ,s.endtime\n","    ,s.sofa_24hours\n","    \n","from sofa s \n","\"\"\"    \n","\n","df_sofa_cleansed = sqlContext.sql(query)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"E0XUbhmtftzR"},"source":["#Impute Last and First value for missing sofa 24 hour scores\n","\n","#Fill in Missing Values with Last Value if avaliable followed by latest value for missing preonset data\n","#Code Reference: Paul Lee's Lab Notebook, https://stackoverflow.com/questions/38131982/forward-fill-missing-values-in-spark-python\n","window = Window.partitionBy('icustay_id')\\\n","       .orderBy('hr')\\\n","       .rowsBetween(-1000000, 0)\n","\n","#colsfill = ['v_heartrate', 'v_sysbp', 'v_diasbp', 'v_meanbp', 'v_resprate', 'v_tempc', 'v_spo2', 'v_glucose']\n","colsfill = ['sofa_24hours']\n","            \n","for col in colsfill:\n","    df_sofa_cleansed = df_sofa_cleansed.withColumn(col, last(col,ignorenulls = True).over(window))   \n","\n","window = Window.partitionBy('icustay_id')\\\n","       .orderBy('hr')\\\n","       .rowsBetween(0, Window.unboundedFollowing)\n","\n","for col in colsfill:\n","    df_sofa_cleansed =df_sofa_cleansed.withColumn(col, first(col,ignorenulls = True).over(window))   \n","    \n","\n","df_sofa_cleansed.registerTempTable('sofa_cleansed')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"isIVvdVDftzS"},"source":["#JOIN SOFA to cohort ts\n","\n","query = \\\n","\"\"\"\n","select \n","    ts.*\n","    --,s.hr\n","    --,s.starttime\n","    --,s.endtime\n","    ,s.sofa_24hours\n","    \n","from cohort_exclusion_ts ts \n","        LEFT JOIN sofa_cleansed s ON (ts.icustay_id = s.icustay_id) AND (ts.timestamp = s.starttime)\n"," \n","where 1=1\n","\"\"\"    \n","\n","df_cohort_cleansed = sqlContext.sql(query)\n","df_cohort_cleansed.registerTempTable('cohort_cleansed')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oxyqH-CEftzS"},"source":["#Determines Diagnosis Sepsis-3 based on SOFA >= 2 over 48 hours prior and 24 hours after suspected infection time limited by icu stay time window. \n","#Seeks increase based on first sofa 24 hour value in time window.\n","query = \\\n","\"\"\"\n","With Inf_W_CTE AS (\n","--Flags Window over Time Series for suspected infection: 48 hrs preceding and 24 post suspicion\n","Select \n","    cc.*\n","    ,CASE WHEN timestamp BETWEEN cc.inf_window_start AND cc.inf_window_end - INTERVAL 1 HOURS Then 1\n","          ELSE 0 \n","          END AS sus_window_flg\n","    \n","from cohort_cleansed as cc\n",")\n","\n",",DIAG_CTE as (\n","--Compares sofa_24hours score with min. score prior to current row and flags when a geq +2 change occurs \n","Select\n","    W.icustay_id\n","    ,W.hour\n","    ,W.sus_window_flg\n","    ,sofa_24hours - (Min(sofa_24hours) OVER(PARTITION BY icustay_id ORDER BY hour ROWS BETWEEN UNBOUNDED PRECEDING AND 1 PRECEDING)) as sofa_24hours_delta\n","    ,CASE WHEN (sofa_24hours - (Min(sofa_24hours) OVER(PARTITION BY icustay_id ORDER BY hour ROWS BETWEEN UNBOUNDED PRECEDING AND 1 PRECEDING))) >= 2 Then 1\n","          ELSE 0\n","          END AS Sepsis3_start_flg\n","          \n","From INF_W_CTE as W\n","Where W.sus_window_flg = 1\n",")\n","\n","Select \n","    cc.*\n","    --,d.sus_window_flg\n","    --,d.sofa_24hours_delta\n","    ,d.Sepsis3_start_flg\n","    ,CASE WHEN (SUM(d.Sepsis3_start_flg) OVER (PARTITION BY cc.icustay_id) >= 1) THEN 1 ELSE 0 END as Sepsis3_diag_flg \n","FROM cohort_cleansed as cc\n","LEFT JOIN DIAG_CTE as d ON (cc.icustay_id = d.icustay_id) AND (cc.hour = d.hour)\n","\"\"\"  \n","\n","df_cohort_diag = sqlContext.sql(query)\n","df_cohort_diag.registerTempTable('cohort_diag')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HyRgEL2UftzT"},"source":["#Find Sepsis Onset Hour\n","\n","query = \\\n","\"\"\"\n","With first_cte as (\n","\n","    Select\n","        cd.icustay_id\n","        ,cd.hour\n","        ,ROW_NUMBER() OVER(PARTITION BY cd.icustay_id order by cd.hour) as rn\n","\n","    from cohort_diag as cd\n","    Where Sepsis3_start_flg = 1\n",")\n","\n","select\n","cd.*\n",",fc.hour as sepsis_onset_hr\n","from cohort_diag cd left join first_cte fc ON (cd.icustay_id = fc.icustay_id) AND (cd.hour = fc.hour) AND fc.rn = 1 \n","\"\"\"  \n","df_cohort_diag_onset = sqlContext.sql(query)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VkCpd_nyftzU"},"source":["#Impute Last and First value for sepsis onset hour\n","\n","#Fill in Missing Values with Last Value if avaliable followed by latest value for missing preonset data\n","#Code Reference: Paul Lee's Lab Notebook, https://stackoverflow.com/questions/38131982/forward-fill-missing-values-in-spark-python\n","window = Window.partitionBy('icustay_id')\\\n","       .orderBy('hour')\\\n","       .rowsBetween(-1000000, 0)\n","\n","colsfill = ['sepsis_onset_hr']\n","            \n","for col in colsfill:\n","    df_cohort_diag_onset = df_cohort_diag_onset.withColumn(col, last(col,ignorenulls = True).over(window))   \n","\n","window = Window.partitionBy('icustay_id')\\\n","       .orderBy('hour')\\\n","       .rowsBetween(0, Window.unboundedFollowing)\n","\n","for col in colsfill:\n","    df_cohort_diag_onset =df_cohort_diag_onset.withColumn(col, first(col,ignorenulls = True).over(window))   \n","    \n","df_cohort_diag_onset.registerTempTable('cohort_diag_onset')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xUArXIBmftzV"},"source":["#Determines obsevation and prediction time windows\n","query = \\\n","\"\"\"\n","with window_cte as (\n","    select icustay_id\n","           --,round(((max(icu_length_of_stay)*24)/4),0) as control_index_hr\n","           --,(round(((max(icu_length_of_stay)*24)/4),0) -12) as control_start_hr\n","           ,max(hour) as control_index_hr\n","           ,(max(hour) - 12) as control_start_hr\n","           ,max(sepsis_onset_hr - 3) as case_index_hr\n","           ,(max(sepsis_onset_hr) -3 - 12) as case_start_hr\n","           \n","    from cohort_diag_onset \n","    --where sepsis_onset_hr is NULL\n","    group by icustay_id\n",")\n","\n","select cdo.* \n","from cohort_diag_onset as cdo \n","left join window_cte as cc on cdo.icustay_id = cc.icustay_id\n","\n","where 1=1\n","      and (((hour <= case_index_hr) and (hour > case_start_hr)) \n","             or ((sepsis_onset_hr is NULL) and (hour <= control_index_hr) and (hour > control_start_hr))) \n","\"\"\"\n","\n","df_cohort_diag_onset_final = sqlContext.sql(query)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"g01f5RdlftzW"},"source":["#Balance Dataset for better model performance\n","pandasDF = df_cohort_diag_onset_final.toPandas()\n","\n","icustay_id_sepsis3 = pandasDF[pandasDF['Sepsis3_diag_flg'] == 1]\n","print(icustay_id_sepsis3['icustay_id'].nunique())\n","\n","icustay_id_nonsepsis3 = pandasDF[pandasDF['Sepsis3_diag_flg'] != 1]\n","print(icustay_id_nonsepsis3['icustay_id'].nunique())\n","\n","l_icustay_id_nonsepsis3 = list(icustay_id_nonsepsis3['icustay_id'].unique())\n","print(len(l_icustay_id_nonsepsis3))\n","\n","random.seed(10)\n","l_icustay_id_nonsepsis3_sample = sample(l_icustay_id_nonsepsis3,icustay_id_sepsis3['icustay_id'].nunique())\n","print(len(l_icustay_id_nonsepsis3_sample))\n","\n","idx = icustay_id_nonsepsis3.icustay_id.isin(l_icustay_id_nonsepsis3_sample)\n","icustay_id_nonsepsis3_sample = icustay_id_nonsepsis3[idx]\n","print(icustay_id_nonsepsis3_sample['icustay_id'].nunique())\n","\n","df_final = icustay_id_sepsis3.append(icustay_id_nonsepsis3_sample, ignore_index=True)\n","print((df_final['icustay_id'].nunique()))\n","\n","df_final.to_csv('gs://peaceful-bruin-307600/cohort_v1.csv',index=False)"],"execution_count":null,"outputs":[]}]}